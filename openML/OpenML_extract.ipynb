{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b461891-ac9c-4eda-88ce-6455feebd0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully in Croissant format!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Specify the dataset ID\n",
    "# dataset_openml = 333  # Replace with your desired dataset ID\n",
    "\n",
    "# URL to download the dataset in Croissant format\n",
    "download_urlml = f\"https://openml1.win.tue.nl/datasets/0000/1464/dataset_1464_croissant.json\"\n",
    "# https://openml1.win.tue.nl/datasets/0000/1464/dataset_1464_croissant.json\n",
    "\n",
    "# Make a request to download the dataset\n",
    "response_openml = requests.get(download_urlml)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response_openml.status_code == 200:\n",
    "    # Save the content to a file\n",
    "    with open('dataset_333.json', 'wb') as file:\n",
    "        file.write(response_openml.content)\n",
    "    print(\"Dataset downloaded successfully in Croissant format!\")\n",
    "else:\n",
    "    print(\"Error: Unable to download the dataset.\")\n",
    "    print(\"Status code:\", response_openml.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcf90e30-6ee0-4cd7-a299-d6a86a8f1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ae444c3-f055-4e95-8e1a-fb3546139e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# List all datasets and their properties\n",
    "data = openml.datasets.list_datasets(output_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63d9ad50-0ae9-4b1f-80ae-0fb39d90edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5760 entries, 2 to 46351\n",
      "Data columns (total 16 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   did                                 5760 non-null   int64  \n",
      " 1   name                                5760 non-null   object \n",
      " 2   version                             5760 non-null   int64  \n",
      " 3   uploader                            5760 non-null   object \n",
      " 4   status                              5760 non-null   object \n",
      " 5   format                              5760 non-null   object \n",
      " 6   MajorityClassSize                   2392 non-null   float64\n",
      " 7   MaxNominalAttDistinctValues         1410 non-null   float64\n",
      " 8   MinorityClassSize                   2392 non-null   float64\n",
      " 9   NumberOfClasses                     4381 non-null   float64\n",
      " 10  NumberOfFeatures                    5715 non-null   float64\n",
      " 11  NumberOfInstances                   5715 non-null   float64\n",
      " 12  NumberOfInstancesWithMissingValues  5715 non-null   float64\n",
      " 13  NumberOfMissingValues               5715 non-null   float64\n",
      " 14  NumberOfNumericFeatures             5715 non-null   float64\n",
      " 15  NumberOfSymbolicFeatures            5715 non-null   float64\n",
      "dtypes: float64(10), int64(2), object(4)\n",
      "memory usage: 765.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34bd145a-2e75-4436-8868-bb37ba8c5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of OpenML datasets ID\n",
    "openml_datases_ids = data['did'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78c3be-7f5a-413f-82f2-5ac2b78f6693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b23a3eb1-197f-4e30-9bbb-e71f36249fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_datasets = [1464, 333, 1510, 1489, 1487, 1485, 1130, 1142, 1138, 1161]\n",
    "openml_subset = [1464, 333, 1510, 1489]\n",
    "def croissant_OpenML(data_id:list, condition):\n",
    "    for i in data_id:\n",
    "        url_openml = f\"https://openml1.win.tue.nl/datasets/0000/{i}/dataset_{i}_croissant.jsonld\"\n",
    "        # https://openml1.win.tue.nl/datasets/0000/1464/dataset_1464_croissant.json\n",
    "    \n",
    "        directory = Path('OpenML_Results')\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        dirpath = os.path.abspath('OpenML_Results')  \n",
    "        filename = 'dataset_'+str(i)+'_croissant' +'.jsonld'\n",
    "        otput = os.path.join(dirpath , filename)\n",
    "        # Make a request to download the dataset\n",
    "        response_openml = requests.get(download_urlml)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response_openml.status_code == 200:\n",
    "            # Save the content to a file\n",
    "            with open(otput, 'wb') as file:\n",
    "                file.write(response_openml.content)\n",
    "            # print(\"Dataset downloaded successfully in Croissant format!\")\n",
    "        else:\n",
    "            print(\"Error: Unable to download the dataset.\")\n",
    "            print(\"Status code:\", response_openml.status_code)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8182b348-fb44-4f03-9267-fc40e69aafd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n"
     ]
    }
   ],
   "source": [
    "croissant_OpenML(openml_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc9ae75d-02d7-44cc-8b52-4492638ba514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n",
      "Dataset downloaded successfully in Croissant format!\n"
     ]
    }
   ],
   "source": [
    "openml_datasets = [1464, 333, 1510, 1489, 1487, 1485, 1130, 1142, 1138, 1161]\n",
    "openml_subset = [1464, 333, 1510, 1489]\n",
    "\n",
    "def my_function(condition, openml_datasets, openml_subset):\n",
    "    if condition:\n",
    "        # Execute code using openml_subset\n",
    "        croissant_OpenML(openml_subset)\n",
    "            \n",
    "    else:\n",
    "        # Execute code using openml_datasets\n",
    "         croissant_OpenML(openml_datasets)\n",
    "       \n",
    "\n",
    "condition = True  # Change this to False to use openml_datasets\n",
    "\n",
    "my_function(condition, openml_datasets, openml_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "868d3f1c-4e3d-4296-bff3-5b3720ce58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_datasets = ['neuralwork/arxiver',\n",
    " 'fka/awesome-chatgpt-prompts',\n",
    " 'nvidia/HelpSteer2',\n",
    " 'LLM360/TxT360',\n",
    " 'Marqo/marqo-GS-10M',\n",
    " 'mlabonne/open-perfectblend']\n",
    "for j in hf_datasets:\n",
    "    url_hf = f\"https://huggingface.co/api/datasets/{j}/croissant/\"\n",
    "    # https://openml1.win.tue.nl/datasets/0000/1464/dataset_1464_croissant.json\n",
    "\n",
    "    directory_hf = Path('HF')\n",
    "    directory_hf.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    dirpath_hf = os.path.abspath('HF')  \n",
    "    filename_hf = j.replace('/','_') +'.jsonld'\n",
    "    \n",
    "    \n",
    "    otput1 = os.path.join(dirpath_hf , filename_hf)\n",
    "    # Make a request to download the dataset\n",
    "    response_hf = requests.get(url_hf)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response_hf.status_code == 200:\n",
    "        # Save the content to a file\n",
    "        with open(otput1, 'w', encoding='utf-8') as file:\n",
    "            abc = response_hf.json()\n",
    "            pretty_jsonld = json.dumps(abc, indent=2, ensure_ascii=False)\n",
    "            # jsonld_data = json.load(response_hf.content)\n",
    "            file.write(pretty_jsonld)\n",
    "            # Pretty print the JSON-LD data\n",
    "           \n",
    "    else:\n",
    "        print(\"Error: Unable to download the dataset.\")\n",
    "        print(\"Status code:\", response_hf.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde0f214-595e-4b27-9a19-0e03d24f3ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to download dataset 0333. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_openml_dataset(dataset_id: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Download an OpenML dataset in Croissant format.\n",
    "\n",
    "    Parameters:\n",
    "    dataset_id (str): The ID of the dataset to download.\n",
    "    output_dir (str): The directory where the dataset will be saved.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define the URL for the dataset in Croissant format\n",
    "    url = f\"https://openml1.win.tue.nl/datasets/0000/{dataset_id}/\"\n",
    "\n",
    "    # Define the output file path\n",
    "    output_filepath = os.path.join(output_dir, f\"dataset_{dataset_id}+'_croissant'.json\")\n",
    "\n",
    "    # Make a request to download the dataset\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the dataset to a file\n",
    "        with open(output_filepath, 'w', encoding=\"utf-8\") as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Dataset {dataset_id} downloaded successfully to: {output_filepath}\")\n",
    "    else:\n",
    "        print(f\"Error: Unable to download dataset {dataset_id}. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_id = \"0333\"  # Replace with the desired dataset ID\n",
    "    output_directory = \"openml_datasets\"\n",
    "    download_openml_dataset(dataset_id, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfd517-af04-4855-acb0-03cf58d803cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8ea1baa-7534-4463-a4ac-b407388e61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'parentField', 'rai', '@vocab', 'isLiveDataset', 'key', 'conformsTo', 'source', 'column', 'md5', 'sc', 'jsonPath', 'format', '@language', 'separator', 'references', 'replace', 'examples', 'field', 'data', 'fileObject', 'fileProperty', 'regex', 'repeated', 'extract', 'citeAs', 'transform', 'recordSet', 'includes', 'dct', 'fileSet', 'subField', 'dataType', 'path', 'cr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data from C:\\Users\\Solanki\\Downloads\\response_1729761158832.json: Found no node in graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mlcroissant import Dataset\n",
    "\n",
    "def load_croissant_data(json_file: str):\n",
    "    \"\"\"\n",
    "    Load Croissant data from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    json_file_path (str): The path to the JSON file in Croissant format.\n",
    "\n",
    "    Returns:\n",
    "    Dataset: The loaded Croissant dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset using mlcroissant\n",
    "        dataset = Dataset(json_file)\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {json_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    json_file = r\"C:\\Users\\Solanki\\Downloads\\response_1729761158832.json\" # Replace with your JSON file path\n",
    "    croissant_data = load_croissant_data(json_file)\n",
    "\n",
    "    if croissant_data is not None:\n",
    "        print(\"Data loaded successfully!\")\n",
    "        print(croissant_data)  # Print or process the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60296573-eea0-4059-a5fb-2696e236138b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59f7f95b-8735-4703-9736-05ab61ec0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Define the dataset ID for Croissant\n",
    "# dataset_id = 61  # Replace with the correct dataset ID if necessary\n",
    "\n",
    "# Define the URL for the dataset download\n",
    "url =  'https://www.openml.org/api/v1/json/data/61'\n",
    "\n",
    "# Make a request to the OpenML API to get the dataset\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the content to a file\n",
    "    with open('croissant_dataset123.json', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: Unable to download the dataset.\")\n",
    "    print(\"Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1bb4b36-42bc-4a3d-a6e1-1127cc5cfaf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlcroissant\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmlc\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepositories/BioHackathon24/dataset_333.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 6\u001b[0m   content \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[38;5;241m.\u001b[39mto_json()\n\u001b[0;32m      7\u001b[0m   content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(content, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(content)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import mlcroissant as mlc\n",
    "\n",
    "\n",
    "with open(\"Repositories/BioHackathon24/dataset_333.json\", \"w\") as f:\n",
    "  content = metadata.to_json()\n",
    "  content = json.dumps(content, indent=2)\n",
    "  print(content)\n",
    "  f.write(content)\n",
    "  f.write(\"\\n\")  # Terminate file with newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9415f7d1-7ac5-47d0-a030-ea7a33773462",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File C:\\Users\\Solanki\\Downloads\\.jsonld does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonld\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSolanki\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.jsonld\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, jsonld, debug, mapping)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\datasets.py:93\u001b[0m, in \u001b[0;36mDataset.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m Metadata\u001b[38;5;241m.\u001b[39mfrom_json(ctx\u001b[38;5;241m=\u001b[39mctx, json_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m \u001b[43mMetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjsonld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\structure_graph\\nodes\\metadata.py:431\u001b[0m, in \u001b[0;36mMetadata.from_file\u001b[1;34m(cls, ctx, file)\u001b[0m\n\u001b[0;32m    429\u001b[0m     json_ \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json(ctx\u001b[38;5;241m=\u001b[39mctx, json_\u001b[38;5;241m=\u001b[39mjson_)\n\u001b[1;32m--> 431\u001b[0m folder, json_ \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_file_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m ctx\u001b[38;5;241m.\u001b[39mfolder \u001b[38;5;241m=\u001b[39m folder\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json(ctx\u001b[38;5;241m=\u001b[39mctx, json_\u001b[38;5;241m=\u001b[39mjson_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\structure_graph\\graph.py:46\u001b[0m, in \u001b[0;36mfrom_file_to_json\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     44\u001b[0m filepath \u001b[38;5;241m=\u001b[39m epath\u001b[38;5;241m.\u001b[39mPath(filepath)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mopen() \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     48\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mValueError\u001b[0m: File C:\\Users\\Solanki\\Downloads\\.jsonld does not exist."
     ]
    }
   ],
   "source": [
    "dataset = mlc.Dataset(jsonld=r'C:\\Users\\Solanki\\Downloads\\jsonld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9bbd074-4274-44c7-9fc0-6b3e637aa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'parentField', 'rai', '@vocab', 'isLiveDataset', 'key', 'conformsTo', 'source', 'column', 'md5', 'sc', 'jsonPath', 'format', '@language', 'separator', 'references', 'replace', 'examples', 'field', 'data', 'fileObject', 'fileProperty', 'regex', 'repeated', 'extract', 'citeAs', 'transform', 'recordSet', 'includes', 'dct', 'fileSet', 'subField', 'dataType', 'path', 'cr'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Found no node in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlcroissant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonld\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/api/datasets/barilan/blog_authorship_corpus/croissant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, jsonld, debug, mapping)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\datasets.py:93\u001b[0m, in \u001b[0;36mDataset.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m Metadata\u001b[38;5;241m.\u001b[39mfrom_json(ctx\u001b[38;5;241m=\u001b[39mctx, json_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m \u001b[43mMetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjsonld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\structure_graph\\nodes\\metadata.py:430\u001b[0m, in \u001b[0;36mMetadata.from_file\u001b[1;34m(cls, ctx, file)\u001b[0m\n\u001b[0;32m    428\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(file)\n\u001b[0;32m    429\u001b[0m     json_ \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m folder, json_ \u001b[38;5;241m=\u001b[39m from_file_to_json(file)\n\u001b[0;32m    432\u001b[0m ctx\u001b[38;5;241m.\u001b[39mfolder \u001b[38;5;241m=\u001b[39m folder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\structure_graph\\nodes\\metadata.py:443\u001b[0m, in \u001b[0;36mMetadata.from_json\u001b[1;34m(cls, ctx, json_)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Metadata` from JSON.\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m ctx\u001b[38;5;241m.\u001b[39mrdf \u001b[38;5;241m=\u001b[39m Rdf\u001b[38;5;241m.\u001b[39mfrom_json(ctx, json_)\n\u001b[1;32m--> 443\u001b[0m jsonld \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_jsonld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_jsonld(ctx\u001b[38;5;241m=\u001b[39mctx, jsonld\u001b[38;5;241m=\u001b[39mjsonld)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlcroissant\\_src\\core\\json_ld.py:217\u001b[0m, in \u001b[0;36mexpand_jsonld\u001b[1;34m(data, ctx)\u001b[0m\n\u001b[0;32m    215\u001b[0m nodes \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mserialize(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson-ld\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m nodes \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(nodes)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m nodes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound no node in graph\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Find the entry node (schema.org/Dataset). If None found, will raise an error.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m entry_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((record \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m nodes \u001b[38;5;28;01mif\u001b[39;00m _is_dataset_node(record)), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Found no node in graph"
     ]
    }
   ],
   "source": [
    "from mlcroissant import Dataset\n",
    "ds = Dataset(jsonld=\"https://huggingface.co/api/datasets/barilan/blog_authorship_corpus/croissant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734c916-4b50-4bab-88d3-934ab67a97af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
